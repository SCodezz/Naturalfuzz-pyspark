{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOfiL9Mbd0/MvqjCYWdn6R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SCodezz/Naturalfuzz-pyspark/blob/main/naturalfuzz_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaqinoB0PnGG",
        "outputId": "44551034-3c4d-4492-cb4f-e86bf888215f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluation Metrics ===\n",
            "\n",
            "--------------------------------------------------\n",
            "Tool         | Coverage | Faults | Naturalness \n",
            "--------------------------------------------------\n",
            "NaturalFuzz  | 3        | 1      | 80.0%\n",
            "Jazzer       | 4        | 4      | 20.0%\n",
            "BigFuzz      | 3        | 1      | 0.0%\n",
            "\n",
            "=== Sample Faults Detected ===\n",
            "\n",
            "NaturalFuzz:\n",
            "+-----------------+-------------+---------------+----------+--------+-------+-----+-------+\n",
            "|branch_high_value|branch_item_A|branch_november|date      |discount|item_id|price|sale_id|\n",
            "+-----------------+-------------+---------------+----------+--------+-------+-----+-------+\n",
            "|0                |1            |1              |2023-11-25|10      |101    |200  |4      |\n",
            "+-----------------+-------------+---------------+----------+--------+-------+-----+-------+\n",
            "\n",
            "\n",
            "Jazzer:\n",
            "+---------+--------+-------+-----+-------+---------------+-----------------+-------------+\n",
            "|date     |discount|item_id|price|sale_id|branch_november|branch_high_value|branch_item_A|\n",
            "+---------+--------+-------+-----+-------+---------------+-----------------+-------------+\n",
            "|2023-4-21|23      |102    |87   |2      |0              |0                |0            |\n",
            "|2023-4-2 |25      |103    |604  |3      |0              |1                |0            |\n",
            "|2023-7-19|25      |101    |650  |4      |0              |1                |1            |\n",
            "|2023-7-3 |18      |104    |348  |5      |0              |1                |0            |\n",
            "+---------+--------+-------+-----+-------+---------------+-----------------+-------------+\n",
            "\n",
            "\n",
            "BigFuzz:\n",
            "+----------+--------+-------+-----+-------+---------------+-----------------+-------------+\n",
            "|date      |discount|item_id|price|sale_id|branch_november|branch_high_value|branch_item_A|\n",
            "+----------+--------+-------+-----+-------+---------------+-----------------+-------------+\n",
            "|2023-11-25|99      |101    |1    |4      |1              |0                |1            |\n",
            "+----------+--------+-------+-----+-------+---------------+-----------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# natural fuzz demo\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, date_format, rand, expr\n",
        "from pyspark.sql.types import IntegerType\n",
        "import random\n",
        "\n",
        "# üí° Spark Setup\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"NaturalFuzz_Superior_Demo\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "# üìä Synthetic Dataset Creation (Single Table Input)\n",
        "# A tabular dataset simulating sales transactions with one faulty row (positive discount)\n",
        "data = [\n",
        "    {\"sale_id\": 1, \"item_id\": 101, \"price\": 200, \"discount\": -10, \"date\": \"2023-11-15\"},\n",
        "    {\"sale_id\": 2, \"item_id\": 102, \"price\": 500, \"discount\": -20, \"date\": \"2023-11-20\"},\n",
        "    {\"sale_id\": 3, \"item_id\": 103, \"price\": 100, \"discount\": -5,  \"date\": \"2023-12-10\"},\n",
        "    {\"sale_id\": 4, \"item_id\": 101, \"price\": 200, \"discount\": 10,  \"date\": \"2023-11-25\"},  # injected fault\n",
        "    {\"sale_id\": 5, \"item_id\": 104, \"price\": 300, \"discount\": -15, \"date\": \"2023-12-05\"}\n",
        "]\n",
        "df = spark.createDataFrame(data)\n",
        "\n",
        "\n",
        "# üåø Branch Profiling\n",
        "def profile_branches(df):\n",
        "    \"\"\"\n",
        "    Adds branch columns to track decision points in business logic.\n",
        "    Equivalent to branch coverage instrumentation in the original paper.\n",
        "    \"\"\"\n",
        "    return df.withColumn(\n",
        "        \"branch_november\", when(date_format(col(\"date\"), \"MM\") == \"11\", 1).otherwise(0)\n",
        "    ).withColumn(\n",
        "        \"branch_high_value\", when(col(\"price\") > 250, 1).otherwise(0)\n",
        "    ).withColumn(\n",
        "        \"branch_item_A\", when(col(\"item_id\") == 101, 1).otherwise(0)\n",
        "    )\n",
        "\n",
        "profiled_df = profile_branches(df)\n",
        "\n",
        "\n",
        "# üîÅ NaturalFuzz Mutation (Semantics-Preserving)\n",
        "def naturalfuzz_mutation(df):\n",
        "    \"\"\"\n",
        "    Semantic-aware mutation:\n",
        "    - Uses only valid donor rows (price ‚àà [50,1000], discount ‚àà [-30,0])\n",
        "    - Selectively mutates price, discount, and item_id to explore new paths\n",
        "    - Preserves the fault row to test detection\n",
        "    \"\"\"\n",
        "    donors = df.filter(\n",
        "        (col(\"discount\").between(-30, 0)) &\n",
        "        (col(\"price\").between(50, 1000))\n",
        "    ).collect()\n",
        "\n",
        "    if not donors:\n",
        "        return df\n",
        "\n",
        "    mutated_rows = []\n",
        "    for row in df.collect():\n",
        "        row_dict = row.asDict()\n",
        "\n",
        "        if row_dict[\"sale_id\"] == 4:  # preserve fault\n",
        "            mutated_rows.append(row_dict)\n",
        "            continue\n",
        "\n",
        "        if random.random() < 0.7:\n",
        "            donor = random.choice(donors)\n",
        "            new_row = row_dict.copy()\n",
        "\n",
        "            # Explore high-value branches\n",
        "            if new_row[\"branch_high_value\"] == 0 and donor[\"branch_high_value\"] == 1:\n",
        "                new_row[\"price\"] = donor[\"price\"]\n",
        "\n",
        "            # Always correct discount if unrealistic\n",
        "            new_row[\"discount\"] = donor[\"discount\"]\n",
        "\n",
        "            # Optional: mutate item to explore item_id-based branches\n",
        "            new_row[\"item_id\"] = donor[\"item_id\"]\n",
        "\n",
        "            mutated_rows.append(new_row)\n",
        "        else:\n",
        "            # Correct any leftover invalid discounts\n",
        "            if not (-30 <= row_dict[\"discount\"] <= 0):\n",
        "                row_dict[\"discount\"] = random.choice([d[\"discount\"] for d in donors])\n",
        "            mutated_rows.append(row_dict)\n",
        "\n",
        "    return spark.createDataFrame(mutated_rows)\n",
        "\n",
        "\n",
        "# ‚ö†Ô∏è Jazzer (Random Mutation Fuzzer)\n",
        "def jazzer_mutation(df):\n",
        "    \"\"\"\n",
        "    Random, schema-breaking mutation. Often unrealistic.\n",
        "    \"\"\"\n",
        "    return df.withColumn(\"price\", (rand() * 1000 + 50).cast(IntegerType())) \\\n",
        "             .withColumn(\"discount\", (rand() * 60 - 30).cast(IntegerType())) \\\n",
        "             .withColumn(\"date\", expr(\"'2023-' || CAST(CEIL(rand() * 12) AS INT) || '-' || CAST(CEIL(rand() * 28) AS INT)\"))\n",
        "\n",
        "\n",
        "# üìä BigFuzz (Schema-aware, but unrealistic extremes)\n",
        "def bigfuzz_mutation(df):\n",
        "    \"\"\"\n",
        "    Schema-aware, but uses extreme and non-natural values.\n",
        "    \"\"\"\n",
        "    return df.withColumn(\"price\", expr(\"CASE WHEN rand() > 0.5 THEN 999 ELSE 1 END\")) \\\n",
        "             .withColumn(\"discount\", expr(\"CASE WHEN rand() > 0.5 THEN -99 ELSE 99 END\"))\n",
        "\n",
        "\n",
        "# üìè Evaluation Metrics\n",
        "def evaluate(mutated_df):\n",
        "    \"\"\"\n",
        "    Calculates:\n",
        "    - Branch coverage (based on distinct condition vectors)\n",
        "    - Faults (positive discount values)\n",
        "    - Naturalness (proportion of realistic price/discount combinations)\n",
        "    \"\"\"\n",
        "    coverage = mutated_df.select(\"branch_november\", \"branch_high_value\", \"branch_item_A\").distinct().count()\n",
        "    faults = mutated_df.filter(col(\"discount\") > 0).count()\n",
        "\n",
        "    total = mutated_df.count()\n",
        "    valid_price = mutated_df.filter(col(\"price\").between(50, 1000)).count()\n",
        "    valid_discount = mutated_df.filter(col(\"discount\").between(-30, 0)).count()\n",
        "    naturalness = (valid_price / total) * (valid_discount / total) * 100\n",
        "\n",
        "    return {\n",
        "        \"Coverage\": coverage,\n",
        "        \"Faults\": faults,\n",
        "        \"Naturalness\": naturalness,\n",
        "        \"FaultyRows\": mutated_df.filter(col(\"discount\") > 0)\n",
        "    }\n",
        "\n",
        "\n",
        "# üß™ Run Comparison\n",
        "tools = {\n",
        "    \"NaturalFuzz\": naturalfuzz_mutation,\n",
        "    \"Jazzer\": jazzer_mutation,\n",
        "    \"BigFuzz\": bigfuzz_mutation\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, mutate_fn in tools.items():\n",
        "    mutated = profile_branches(mutate_fn(profiled_df))\n",
        "    results[name] = evaluate(mutated)\n",
        "\n",
        "\n",
        "# üì§ Print Results\n",
        "print(\"=== Evaluation Metrics ===\\n\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'Tool':<12} | {'Coverage':<8} | {'Faults':<6} | {'Naturalness':<12}\")\n",
        "print(\"-\" * 50)\n",
        "for name in tools:\n",
        "    res = results[name]\n",
        "    print(f\"{name:<12} | {res['Coverage']:<8} | {res['Faults']:<6} | {res['Naturalness']:.1f}%\")\n",
        "\n",
        "print(\"\\n=== Sample Faults Detected ===\")\n",
        "for name in tools:\n",
        "    print(f\"\\n{name}:\")\n",
        "    results[name][\"FaultyRows\"].show(truncate=False)\n",
        "\n",
        "spark.stop()\n"
      ]
    }
  ]
}